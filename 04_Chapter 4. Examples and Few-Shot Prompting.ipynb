{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 4. Examples and Few-Shot Prompting** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of well-known prompting techniques that use examples, such as zero-shot, one-shot, and few-shot prompting. By understanding each approach and the principles of designing effective examples, you can significantly enhance the performance of Solar. \n",
    "\n",
    "This chapter is based on Prompt `Type C`:  Instruction + Context + **Example** + Output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "- Use `Ctrl + F` (Windows) or `Cmd + F` (Mac) to locate specific sections by title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4.1 Zero-Shot Prompting**\n",
    "\n",
    "    - 4.1.1 Introduction\n",
    "\n",
    "    - 4.1.2 Example\n",
    "\n",
    "    - 4.1.3 Practice\n",
    "\n",
    "\n",
    "- **4.2 One-Shot Prompting**\n",
    "\n",
    "    - 4.2.1 Introduction\n",
    "\n",
    "    - 4.2.2 Example\n",
    "\n",
    "    - 4.2.3 Practice\n",
    "\n",
    "\n",
    "- **4.3 Few-Shot Prompting**\n",
    "\n",
    "    - 4.3.1 Introduction\n",
    "\n",
    "    - 4.3.2 Examples\n",
    "\n",
    "        - (1) Exemplar Quantity\n",
    "\n",
    "        - (2) Exemplar Similarity\n",
    "\n",
    "        - (3) Exemplar Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Retrieve the OPENAI_API_KEY variable from the IPython store\n",
    "%store -r OPENAI_API_KEY\n",
    "\n",
    "try:\n",
    "    if OPENAI_API_KEY:\n",
    "        print(\"Success!\")\n",
    "except NameError as ne:\n",
    "    print(f\"Since, {ne}\")\n",
    "    print(\"Please, insert your API key.\")\n",
    "    OPENAI_API_KEY = input(\"OPENAI_API_KEY =\")\n",
    "\n",
    "# Set your API key: \n",
    "# OPENAI_API_KEY = \" \" ←- Insert your API key here.\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key= OPENAI_API_KEY,\n",
    "    base_url=\"https://api.openai.com/v1\"\n",
    ")\n",
    "\n",
    "config_model = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"max_tokens\": 2000,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "def get_completion(messages, system_prompt=\"\", config=config_model):\n",
    "    try:\n",
    "        if system_prompt:\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
    "\n",
    "        message = client.chat.completions.create(messages=messages, **config)\n",
    "        return message.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 Zero-Shot Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1.1 Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zero-shot prompting** is a technique where the model is asked to perform a task without any prior examples. There are numerous ways to craft zero-shot prompts. This is one of the powerful features of language models—it allows them to perform various tasks with minimal information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1.2 Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: { neutral } \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"Classify the following text as positive, negative, or neutral. Text: I thought the macaron flavor was just okay. Sentiment: { }\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1.3 Practice**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Translate the term 'artificial tears' from English into Japanese. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"artificial tears\"는 일본어로 \"人工涙液\" (じんこうるいえき, jinkō ruieki)라고 합니다. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"일본어로 번역해줘: artificial tears\" # ←- Insert your prompt here.\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.2 One-Shot Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2.1 Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-shot prompting** is a technique where the model is provided with only one example before it’s asked to complete the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2.2 Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'adore étudier les langues. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"Translate the following sentence into French: I like reading books.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\":\"assistant\",\n",
    "        \"content\": \"J'aime lire des livres.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"Translate the following sentence into French: I love studying language\"\n",
    "    },\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2.3 Practice**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Translate the term 'artificial tears' from English to Japanese using one-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工涙液 (じんこうるいえき) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"일본어로 번역해줘: artificial intelligence\" # ←- Insert your prompt here.\n",
    "    },\n",
    "    {\n",
    "        \"role\":\"assistant\",\n",
    "        \"content\": \"人工知能\"\n",
    "    },\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"일본어로 번역해줘: artificial tears\" # ←- Insert your prompt here.\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.3 Few-Shot Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3.1 Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few-shot prompting** is a technique where the model is given a handful of examples—typically two to five—before it is asked to complete the task. This approach offers the model multiple references for the type of output desired, providing more context and making the output more accurate or aligned with specific patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It's important to note that **few-shot learning** and **few-shot prompting** are distinct concepts. Few-shot learning is a broader machine learning approach focused on adapting model parameters with only a few examples. In contrast, **few-shot prompting** specifically applies to prompt design in generative AI, where model parameters remain unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3.2 Examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"2+10:\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"twelve\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"4+52:\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"fifty-six\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"100+301:\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to highlight **three ways** to design effective examples:\n",
    "\n",
    "- **Exemplar Quantity**\n",
    "- **Exemplar Similarity**\n",
    "- **Exemplar Format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) Exemplar Quantity**\n",
    "예시의 수량"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly, the quantity of exemplars in the prompt generally improves model\n",
    "performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Thick smog chokes northern India and eastern Pakistan ahead of Diwali.\"\n",
      "Subject: \"Thick smog\"\n",
      "Verb: \"chokes\"\n",
      "Direct Objects: \"northern India and eastern Pakistan\"\n",
      "Prepositional Phrase: \"ahead of Diwali\"\n",
      "Analysis: The sentence follows a subject-verb-object structure, with a prepositional phrase providing additional context about the timing related to the action. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"The cat sleeps.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"Sentence: \"The cat sleeps.\"\n",
    "Subject: \"The cat\"\n",
    "Verb: \"sleeps\"\n",
    "Object: None\n",
    "Analysis: Simple subject-verb sentence structure with a single actor performing an action.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"She reads books.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"Sentence: \"She reads books.\"\n",
    "Subject: \"She\"\n",
    "Verb: \"reads\"\n",
    "Object: \"books\"\n",
    "Analysis: Subject-verb-object structure, indicating the action is directed toward an object.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"They dance gracefully.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"Sentence: \"They dance gracefully.\"\n",
    "Subject: \"They\"\n",
    "Verb: \"dance\"\n",
    "Adverb: \"gracefully\"\n",
    "Analysis: Subject-verb-adverb structure, with the adverb modifying how the action is performed.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"The sun rises in the east.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"Sentence: \"The sun rises in the east.\"\n",
    "Subject: \"The sun\"\n",
    "Verb: \"rises\"\n",
    "Prepositional Phrase: \"in the east\"\n",
    "Analysis: Subject-verb-prepositional phrase structure, adding context about the action's location.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Thick smog chokes northern India and eastern Pakistan ahead of Diwali.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down the sentence \"Thick smog chokes northern India and eastern Pakistan ahead of Diwali\" into its components:\n",
      "\n",
      "1. **Subject**: \n",
      "   - \"Thick smog\"\n",
      "     - \"Thick\" (adjective) describes the noun \"smog.\"\n",
      "     - \"Smog\" (noun) is the main subject of the sentence.\n",
      "\n",
      "2. **Verb**: \n",
      "   - \"chokes\" (verb) is the action that the subject (thick smog) is performing.\n",
      "\n",
      "3. **Direct Object**: \n",
      "   - There is no direct object in this sentence because \"chokes\" is an intransitive verb; it does not require a direct object to complete its meaning.\n",
      "\n",
      "4. **Prepositional Phrases**:\n",
      "   - \"northern India and eastern Pakistan\"\n",
      "     - \"northern\" (adjective) modifies \"India.\"\n",
      "     - \"India\" (noun) is the first part of the compound noun phrase.\n",
      "     - \"and\" (conjunction) connects \"India\" and \"eastern Pakistan.\"\n",
      "     - \"eastern\" (adjective) modifies \"Pakistan.\"\n",
      "     - \"Pakistan\" (noun) is the second part of the compound noun phrase.\n",
      "   - This phrase acts as the complement to the verb, indicating where the choking action is taking place.\n",
      "\n",
      "5. **Adverbial Phrase**:\n",
      "   - \"ahead of Diwali\"\n",
      "     - \"ahead of\" (preposition) introduces the phrase.\n",
      "     - \"Diwali\" (noun) is the object of the preposition.\n",
      "   - This phrase provides temporal context, indicating when the action is occurring.\n",
      "\n",
      "In summary, the structure of the sentence can be outlined as follows:\n",
      "\n",
      "- **Subject**: Thick smog\n",
      "- **Verb**: chokes\n",
      "- **Prepositional Phrase**: northern India and eastern Pakistan (indicating the location affected by the action)\n",
      "- **Adverbial Phrase**: ahead of Diwali (indicating the time of the action) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# without an example\n",
    "\n",
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"\"\"Please analyze and define the sentence components in the following sentence.\n",
    "        sentence: \"Thick smog chokes northern India and eastern Pakistan ahead of Diwali.\"\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observation: 예시를 제공하면 모델이 해당 예시에서 사용된 형식에 맞춰 응답하는 것을 확인할 수 있습니다. 복잡하고 다양한 문장 구조를 포함하더라도, 여러 예시를 사용하여 모델을 안내하면 작업을 효과적으로 수행하는 데 도움이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) Exemplar Similarity**\n",
    "예시의 유사성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select exemplars that are similar to your task. For example, if you are summarizing a news article, using exemplars in the same format will yield the best results you desire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following prompt example, you can see that the summary results use **a consistent response format(형식의 유사성)** as an example. By increasing the consistency of the format, you can achieve more accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Open Source Definition / Requires detailed design and training data disclosure./\n",
      "#Usage Rights / Freedom to modify and use without permission./\n",
      "#Misuse of Term / Many companies falsely claim open source status for their models./ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When examples have the similarities\n",
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"\"\"Read the following text and summarize the key points. Once you finish the summary, organize it as follows:\n",
    "\n",
    "#Keyword 1 / Related key point in one short phrase./\n",
    "#Keyword 2 / Related key point in one short phrase./\n",
    "#Keyword 3 / Related key point in one short phrase./\n",
    "\n",
    "<text>\n",
    "To be considered open source under the OSAID, an AI model has to provide enough information about its design so that a person could “substantially” recreate it. The model must also disclose any pertinent details about its training data, including the provenance, how the data was processed, and how it can be obtained or licensed.\n",
    "“An open source AI is an AI model that allows you to fully understand how it’s been built,” Maffulli said. “That means that you have access to all the components, such as the complete code used for training and data filtering.”\n",
    "The OSAID also lays out usage rights developers should expect with open source AI, like the freedom to use the model for any purpose and modify it without having to ask anyone’s permission. “Most importantly, you should be able to build on top,” added Maffulli.\n",
    "The OSI has no enforcement mechanisms to speak of. It can’t pressure developers to abide by or follow the OSAID. But it does intend to flag models described as “open source” but which fall short of the definition.\n",
    "“Our hope is that when someone tries to abuse the term, the AI community will say, ‘We don’t recognize this as open source,’ and it gets corrected,” Maffulli said. Historically, this has had mixed results, but it isn’t entirely without effect.\n",
    "Many startups and big tech companies, most prominently Meta, have employed the term “open source” to describe their AI model release strategies — but few meet the OSAID’s criteria. For example, Meta mandates that platforms with over 700 million monthly active users request a special license to use its [Llama](https://techcrunch.com/2024/09/08/meta-llama-everything-you-need-to-know-about-the-open-generative-ai-model/) models.\n",
    "Maffulli has been [openly critical](https://www.ft.com/content/397c50d8-8796-4042-a814-0ac2c068361f) of Meta’s decision to call its models “open source.” After discussions with the OSI, Google and Microsoft agreed to drop their use of the term for models that aren’t fully open, but Meta hasn’t, he said.\n",
    "Stability AI, which has long advertised its models as “open,” requires that businesses making more than $1 million in revenue obtain an enterprise license. And French AI upstart Mistral’s license bars the use of certain models and outputs for commercial ventures.\n",
    "A [study](https://www.wired.com/story/the-myth-of-open-source-ai/) last August by researchers at the Signal Foundation, the nonprofit AI Now Institute, and Carnegie Mellon found that many “open source” models are basically open source in name only. The data required to train the models is kept secret, the compute power needed to run them is beyond the reach of many developers, and the techniques to fine-tune them are intimidatingly complex.\n",
    "Instead of democratizing AI, these “open source” projects tend to entrench and expand centralized power, the study’s authors concluded. Indeed, Meta’s Lllama models have [racked up](https://venturebeat.com/ai/meta-leads-open-source-ai-boom-llama-downloads-surge-10x-year-over-year/) hundreds of millions of downloads, and Stability [claims](https://www.prnewswire.com/news-releases/stability-ai-secures-significant-new-investment-from-world-class-investor-group-and-appoints-prem-akkaraju-as-ceo-302181923.html) that its models power up to 80% of all AI-generated imagery.\n",
    "</text>\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When examples don't have the similarities\n",
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"\"\"Read the following text and summarize the key points. Once you finish the summary, organize it as follows:\n",
    "\n",
    "Related key point in one short phrase./Keyword 1\n",
    "Keyword 2 Related key point in two short phrases.\n",
    "Keyword 3/ Related key point in three short phrases.\n",
    "\n",
    "<text>\n",
    "To be considered open source under the OSAID, an AI model has to provide enough information about its design so that a person could “substantially” recreate it. The model must also disclose any pertinent details about its training data, including the provenance, how the data was processed, and how it can be obtained or licensed.\n",
    "“An open source AI is an AI model that allows you to fully understand how it’s been built,” Maffulli said. “That means that you have access to all the components, such as the complete code used for training and data filtering.”\n",
    "The OSAID also lays out usage rights developers should expect with open source AI, like the freedom to use the model for any purpose and modify it without having to ask anyone’s permission. “Most importantly, you should be able to build on top,” added Maffulli.\n",
    "The OSI has no enforcement mechanisms to speak of. It can’t pressure developers to abide by or follow the OSAID. But it does intend to flag models described as “open source” but which fall short of the definition.\n",
    "“Our hope is that when someone tries to abuse the term, the AI community will say, ‘We don’t recognize this as open source,’ and it gets corrected,” Maffulli said. Historically, this has had mixed results, but it isn’t entirely without effect.\n",
    "Many startups and big tech companies, most prominently Meta, have employed the term “open source” to describe their AI model release strategies — but few meet the OSAID’s criteria. For example, Meta mandates that platforms with over 700 million monthly active users request a special license to use its [Llama](https://techcrunch.com/2024/09/08/meta-llama-everything-you-need-to-know-about-the-open-generative-ai-model/) models.\n",
    "Maffulli has been [openly critical](https://www.ft.com/content/397c50d8-8796-4042-a814-0ac2c068361f) of Meta’s decision to call its models “open source.” After discussions with the OSI, Google and Microsoft agreed to drop their use of the term for models that aren’t fully open, but Meta hasn’t, he said.\n",
    "Stability AI, which has long advertised its models as “open,” requires that businesses making more than $1 million in revenue obtain an enterprise license. And French AI upstart Mistral’s license bars the use of certain models and outputs for commercial ventures.\n",
    "A [study](https://www.wired.com/story/the-myth-of-open-source-ai/) last August by researchers at the Signal Foundation, the nonprofit AI Now Institute, and Carnegie Mellon found that many “open source” models are basically open source in name only. The data required to train the models is kept secret, the compute power needed to run them is beyond the reach of many developers, and the techniques to fine-tune them are intimidatingly complex.\n",
    "Instead of democratizing AI, these “open source” projects tend to entrench and expand centralized power, the study’s authors concluded. Indeed, Meta’s Lllama models have [racked up](https://venturebeat.com/ai/meta-leads-open-source-ai-boom-llama-downloads-surge-10x-year-over-year/) hundreds of millions of downloads, and Stability [claims](https://www.prnewswire.com/news-releases/stability-ai-secures-significant-new-investment-from-world-class-investor-group-and-appoints-prem-akkaraju-as-ceo-302181923.html) that its models power up to 80% of all AI-generated imagery.\n",
    "\n",
    "</text>\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "responses = []\n",
    "for i in range(3):\n",
    "    response = get_completion(messages=message)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As seen in the following results, prompts with lower similarity among examples yield a wider variety of outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1\n",
      "**Open Source Definition** / AI models must disclose design and training data details.  \n",
      "**Usage Rights** / Developers can use and modify models freely. No permission needed.  \n",
      "**Misleading Claims** / Many companies misuse the term \"open source.\" Real open source is rare.\n",
      "\n",
      "\n",
      "n = 2\n",
      "**Open Source AI Definition/ Keyword 1**  \n",
      "An AI model must provide sufficient design information for recreation.\n",
      "\n",
      "**Transparency in Training Data/ Keyword 2**  \n",
      "Models must disclose training data details. This includes data provenance, processing methods, and licensing information.\n",
      "\n",
      "**Rights and Limitations/ Keyword 3**  \n",
      "Developers should have the freedom to use and modify models without permission. However, many companies mislabel their models as open source. A study reveals that many \"open source\" models restrict access and enhance centralized control.\n",
      "\n",
      "\n",
      "n = 3\n",
      "**Open Source AI Definition/Keyword 1**  \n",
      "An AI model must provide design details for substantial recreation.\n",
      "\n",
      "**Transparency in Training Data/Keyword 2**  \n",
      "Models must disclose training data provenance and processing. Access to data for licensing is essential.\n",
      "\n",
      "**Usage Rights and Community Response/Keyword 3**  \n",
      "Developers should have freedom to use and modify models. The OSI lacks enforcement but aims to flag misleading “open source” claims. Major companies often misuse the term, failing to meet OSAID criteria.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"n = {i+1}\")\n",
    "    print(responses[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) Exemplar Format**\n",
    "예시의 형식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a common template. The optimal format may vary across tasks. \n",
    "\n",
    "There is evidence indicating that formats frequently found in the training data tend to result in improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- company names: \n",
      "  - SOLAR\n",
      "\n",
      "- personal names: \n",
      "  - (none mentioned)\n",
      "\n",
      "- specific topics:\n",
      "  - large language model (LLM)\n",
      "  - natural language processing (NLP)\n",
      "  - depth up-scaling (DUS)\n",
      "  - mixture-of-experts\n",
      "  - instruction-following capabilities\n",
      "\n",
      "- themes:\n",
      "  - efficient scaling of language models\n",
      "  - model performance\n",
      "  - open access and application in technology \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"\"\"Identify the entities referenced in the text below. \n",
    "\n",
    "Please extract the following four types of entities:\n",
    "- company names: \n",
    "- personal names: \n",
    "- specific topics:\n",
    "- themes:\n",
    "\n",
    "<text>\n",
    "We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, demonstrating superior performance in various natural language processing (NLP) tasks. Inspired by recent efforts to efficiently up-scale LLMs, we present a method for scaling LLMs called depth up-scaling (DUS), which encompasses depthwise scaling and continued pretraining. In contrast to other LLM up-scaling methods that use mixture-of-experts, DUS does not require complex changes to train and inference efficiently. We show experimentally that DUS is simple yet effective in scaling up high-performance LLMs from small ones. Building on the DUS model, we additionally present SOLAR 10.7B-Instruct, a variant fine-tuned for instruction-following capabilities, surpassing Mixtral-8x7B-Instruct. SOLAR 10.7B is publicly available under the Apache 2.0 license, promoting broad access and application in the LLM field.\n",
    "</text>\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages=message)\n",
    "print(response, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When not using a standard format\n",
    "# Prompt:\n",
    "message = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"\"\"Identify the entities referenced in the text below. \n",
    "\n",
    "Please extract the following four types of entities:\n",
    "% % company names\n",
    "% % personal names \n",
    "% % specific topics% % \n",
    "% %  themes % % \n",
    "\n",
    "~text~\n",
    "We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, demonstrating superior performance in various natural language processing (NLP) tasks. Inspired by recent efforts to efficiently up-scale LLMs, we present a method for scaling LLMs called depth up-scaling (DUS), which encompasses depthwise scaling and continued pretraining. In contrast to other LLM up-scaling methods that use mixture-of-experts, DUS does not require complex changes to train and inference efficiently. We show experimentally that DUS is simple yet effective in scaling up high-performance LLMs from small ones. Building on the DUS model, we additionally present SOLAR 10.7B-Instruct, a variant fine-tuned for instruction-following capabilities, surpassing Mixtral-8x7B-Instruct. SOLAR 10.7B is publicly available under the Apache 2.0 license, promoting broad access and application in the LLM field.\n",
    "~text~\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "responses = []\n",
    "for i in range(2):\n",
    "    response = get_completion(messages=message)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When using unusual format symbols or marks, the stability of the results decreases each time they are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1\n",
      "Here are the identified entities from the provided text:\n",
      "\n",
      "**Company Names:**\n",
      "- SOLAR\n",
      "\n",
      "**Personal Names:**\n",
      "- None identified\n",
      "\n",
      "**Specific Topics:**\n",
      "- Large language model (LLM)\n",
      "- Natural language processing (NLP)\n",
      "- Depth up-scaling (DUS)\n",
      "- Mixture-of-experts\n",
      "\n",
      "**Themes:**\n",
      "- Scaling LLMs\n",
      "- Instruction-following capabilities\n",
      "- Open-source software (Apache 2.0 license)\n",
      "- High-performance LLMs\n",
      "\n",
      "\n",
      "n = 2\n",
      "Here are the extracted entities from the provided text:\n",
      "\n",
      "**Company Names:**\n",
      "- None explicitly mentioned.\n",
      "\n",
      "**Personal Names:**\n",
      "- None explicitly mentioned.\n",
      "\n",
      "**Specific Topics:**\n",
      "- SOLAR 10.7B\n",
      "- large language model (LLM)\n",
      "- natural language processing (NLP)\n",
      "- depth up-scaling (DUS)\n",
      "- mixture-of-experts\n",
      "- instruction-following capabilities\n",
      "\n",
      "**Themes:**\n",
      "- Up-scaling methods for language models\n",
      "- Efficiency in training and inference of LLMs\n",
      "- Accessibility and application of LLMs in the field\n",
      "- Performance comparison of language models (SOLAR 10.7B vs. Mixtral-8x7B-Instruct)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(f\"n = {i+1}\")\n",
    "    print(responses[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "[Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). *Language models are few-shot learners.* Advances in Neural Information Processing Systems, 33, 1877-1901.](https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "[Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., ... & Le, Q. V. (2021). *Finetuned language models are zero-shot learners.* arXiv preprint arXiv:2109.01652.](https://arxiv.org/abs/2109.01652)\n",
    "\n",
    "[Work, W. M. I. C. L. *Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?*](https://arxiv.org/abs/2202.12837)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
